{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e71e6fe390>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "from net import CNN\n",
    "from mydataset import MyDataSet\n",
    "from myloss import TripletLoss\n",
    "\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 25\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([   \n",
    "        transforms.Resize([96, 96]),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=(0,0,0),std=(1,1,1))\n",
    "])\n",
    "\n",
    "train_set = MyDataSet('./birds/train/',transform=transform, labels=None)\n",
    "train_loader = Data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_set = MyDataSet('./birds/test/', transform=transform, labels=None)\n",
    "test_loader = Data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross', '004.Groove_billed_Ani', '005.Crested_Auklet', '006.Least_Auklet', '007.Parakeet_Auklet', '008.Rhinoceros_Auklet', '009.Brewer_Blackbird', '010.Red_winged_Blackbird']\n",
      "{'001.Black_footed_Albatross': 0, '002.Laysan_Albatross': 1, '003.Sooty_Albatross': 2, '004.Groove_billed_Ani': 3, '005.Crested_Auklet': 4, '006.Least_Auklet': 5, '007.Parakeet_Auklet': 6, '008.Rhinoceros_Auklet': 7, '009.Brewer_Blackbird': 8, '010.Red_winged_Blackbird': 9}\n",
      "<bound method MyDataSet.__len__ of <mydataset.MyDataSet object at 0x000001E72171E8D0>>\n",
      "['001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross', '004.Groove_billed_Ani', '005.Crested_Auklet', '006.Least_Auklet', '007.Parakeet_Auklet', '008.Rhinoceros_Auklet', '009.Brewer_Blackbird', '010.Red_winged_Blackbird']\n",
      "{'001.Black_footed_Albatross': 0, '002.Laysan_Albatross': 1, '003.Sooty_Albatross': 2, '004.Groove_billed_Ani': 3, '005.Crested_Auklet': 4, '006.Least_Auklet': 5, '007.Parakeet_Auklet': 6, '008.Rhinoceros_Auklet': 7, '009.Brewer_Blackbird': 8, '010.Red_winged_Blackbird': 9}\n",
      "<bound method MyDataSet.__len__ of <mydataset.MyDataSet object at 0x000001E717132748>>\n"
     ]
    }
   ],
   "source": [
    "print(train_set.classes)\n",
    "print(train_set.class_to_idx)\n",
    "print(train_set.__len__)\n",
    "\n",
    "print(test_set.classes)\n",
    "print(test_set.class_to_idx)\n",
    "print(test_set.__len__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=18432, out_features=768, bias=True)\n",
      "  (out): Linear(in_features=768, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "训练三元损失： tensor(4.9664, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(2.2994, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 10 %\n",
      "训练三元损失： tensor(0.3455, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(2.3413, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 16 %\n",
      "EPOCH 1\n",
      "训练三元损失： tensor(0.5293, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(2.2755, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 6 %\n",
      "训练三元损失： tensor(0.5557, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(2.1779, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 18 %\n",
      "EPOCH 2\n",
      "训练三元损失： tensor(0.3400, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(2.3197, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 15 %\n",
      "训练三元损失： tensor(0.3112, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(1.9783, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 22 %\n",
      "EPOCH 3\n",
      "训练三元损失： tensor(0.4819, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(2.0895, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 19 %\n",
      "训练三元损失： tensor(0.2352, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(2.1269, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 16 %\n",
      "EPOCH 4\n",
      "训练三元损失： tensor(0.1262, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(1.9145, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 24 %\n",
      "训练三元损失： tensor(0.3129, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(1.5982, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 21 %\n",
      "EPOCH 5\n",
      "训练三元损失： tensor(0.9593, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(1.0766, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 16 %\n",
      "训练三元损失： tensor(0.3760, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(1.7602, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 24 %\n",
      "EPOCH 6\n",
      "训练三元损失： tensor(0.5924, grad_fn=<MeanBackward0>)\n",
      "训练交叉熵损失： tensor(1.1394, grad_fn=<NllLossBackward>)\n",
      "Accuracy on the test images: 16 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c134fdf9f2e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\mlcc\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\mlcc\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "cross_loss = nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "triplet_loss = TripletLoss(0.5) # 选择损失函数\n",
    "alpha = 0.5\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    print('EPOCH ' + str(epoch))\n",
    "    # for step, (b_x, b_y) in enumerate(train_loader):\n",
    "    for step, (anchor, positive, negative) in enumerate(train_loader):\n",
    "        #output = cnn(b_x)[0]\n",
    "        #loss = loss_func(output, b_y)\n",
    "        anchor_output = cnn(anchor[0])\n",
    "        positive_output = cnn(positive[0])\n",
    "        negative_output = cnn(negative[0])\n",
    "        \n",
    "        #print(anchor_output.detach().numpy().shape)   \n",
    "        #output = torch.stack((anchor_output[0],  positive_output[0], negative_output[0]), dim=0)\n",
    "        #b_y = torch.stack((anchor[1], positive[1], negative[1]), dim=0)\n",
    "        #print(output)\n",
    "        #print(anchor_output[0])\n",
    "        #b_y = torch.zeros(4, 10).scatter_(1, anchor[1].unsqueeze(1), 1).long()\n",
    "        #print(b_y)\n",
    "        \n",
    "        \n",
    "        triplet_result = triplet_loss(anchor_output[1], positive_output[1], negative_output[1])\n",
    "        cross_result = cross_loss(anchor_output[0], anchor[1])\n",
    "        loss = alpha * triplet_result + (1-alpha) * cross_result\n",
    "                                       \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            print('训练三元损失：', triplet_result)\n",
    "            print('训练交叉熵损失：', cross_result)\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for _, (test, _, _) in enumerate(test_loader):\n",
    "                test_output = cnn(test[0])[0]\n",
    "                predicted = torch.max(test_output, 1).indices\n",
    "                labels = test[1]\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            print('Accuracy on the test images: %d %%' % (100 * correct / total))\n",
    "            \n",
    "#             for data in test_loader:\n",
    "#                 images,labels = data\n",
    "#                 outputs = cnn(Variable(images))\n",
    "#                 predicted = torch.max(outputs[0], 1).indices\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum()\n",
    "                \n",
    "#             print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
