{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x285c4e90350>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "from net import CNN\n",
    "from mydataset import MyDataSet\n",
    "from myloss import TripletLoss\n",
    "\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 25\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([   \n",
    "        transforms.Resize([96, 96]),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=(0,0,0),std=(1,1,1))\n",
    "])\n",
    "\n",
    "train_set = MyDataSet('./birds/train/',transform=transform, labels=None)\n",
    "train_loader = Data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_set = MyDataSet('./birds/test/', transform=transform, labels=None)\n",
    "test_loader = Data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross', '004.Groove_billed_Ani', '005.Crested_Auklet', '006.Least_Auklet', '007.Parakeet_Auklet', '008.Rhinoceros_Auklet', '009.Brewer_Blackbird', '010.Red_winged_Blackbird']\n",
      "{'001.Black_footed_Albatross': 0, '002.Laysan_Albatross': 1, '003.Sooty_Albatross': 2, '004.Groove_billed_Ani': 3, '005.Crested_Auklet': 4, '006.Least_Auklet': 5, '007.Parakeet_Auklet': 6, '008.Rhinoceros_Auklet': 7, '009.Brewer_Blackbird': 8, '010.Red_winged_Blackbird': 9}\n",
      "<bound method MyDataSet.__len__ of <mydataset.MyDataSet object at 0x00000285C7E8F908>>\n",
      "['001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross', '004.Groove_billed_Ani', '005.Crested_Auklet', '006.Least_Auklet', '007.Parakeet_Auklet', '008.Rhinoceros_Auklet', '009.Brewer_Blackbird', '010.Red_winged_Blackbird']\n",
      "{'001.Black_footed_Albatross': 0, '002.Laysan_Albatross': 1, '003.Sooty_Albatross': 2, '004.Groove_billed_Ani': 3, '005.Crested_Auklet': 4, '006.Least_Auklet': 5, '007.Parakeet_Auklet': 6, '008.Rhinoceros_Auklet': 7, '009.Brewer_Blackbird': 8, '010.Red_winged_Blackbird': 9}\n",
      "<bound method MyDataSet.__len__ of <mydataset.MyDataSet object at 0x00000285BD8B0B38>>\n"
     ]
    }
   ],
   "source": [
    "print(train_set.classes)\n",
    "print(train_set.class_to_idx)\n",
    "print(train_set.__len__)\n",
    "\n",
    "print(test_set.classes)\n",
    "print(test_set.class_to_idx)\n",
    "print(test_set.__len__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=18432, out_features=768, bias=True)\n",
      "  (out): Linear(in_features=768, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "Accuracy on the test images: 9 %\n",
      "Accuracy on the test images: 10 %\n",
      "EPOCH 1\n",
      "Accuracy on the test images: 12 %\n",
      "Accuracy on the test images: 12 %\n",
      "EPOCH 2\n",
      "Accuracy on the test images: 12 %\n",
      "Accuracy on the test images: 10 %\n",
      "EPOCH 3\n",
      "Accuracy on the test images: 10 %\n",
      "Accuracy on the test images: 10 %\n",
      "EPOCH 4\n",
      "Accuracy on the test images: 5 %\n",
      "Accuracy on the test images: 10 %\n",
      "EPOCH 5\n",
      "Accuracy on the test images: 10 %\n",
      "Accuracy on the test images: 16 %\n",
      "EPOCH 6\n",
      "Accuracy on the test images: 13 %\n",
      "Accuracy on the test images: 10 %\n",
      "EPOCH 7\n",
      "Accuracy on the test images: 7 %\n",
      "Accuracy on the test images: 10 %\n",
      "EPOCH 8\n",
      "Accuracy on the test images: 10 %\n",
      "Accuracy on the test images: 10 %\n",
      "EPOCH 9\n",
      "Accuracy on the test images: 10 %\n",
      "Accuracy on the test images: 6 %\n",
      "EPOCH 10\n",
      "Accuracy on the test images: 13 %\n",
      "Accuracy on the test images: 10 %\n",
      "EPOCH 11\n",
      "Accuracy on the test images: 10 %\n",
      "Accuracy on the test images: 6 %\n",
      "EPOCH 12\n",
      "Accuracy on the test images: 6 %\n",
      "Accuracy on the test images: 12 %\n",
      "EPOCH 13\n",
      "Accuracy on the test images: 12 %\n",
      "Accuracy on the test images: 9 %\n",
      "EPOCH 14\n",
      "Accuracy on the test images: 9 %\n",
      "Accuracy on the test images: 10 %\n",
      "EPOCH 15\n",
      "Accuracy on the test images: 10 %\n",
      "Accuracy on the test images: 7 %\n",
      "EPOCH 16\n",
      "Accuracy on the test images: 11 %\n",
      "Accuracy on the test images: 18 %\n",
      "EPOCH 17\n",
      "Accuracy on the test images: 10 %\n",
      "Accuracy on the test images: 10 %\n",
      "EPOCH 18\n",
      "Accuracy on the test images: 11 %\n",
      "Accuracy on the test images: 9 %\n",
      "EPOCH 19\n",
      "Accuracy on the test images: 12 %\n",
      "Accuracy on the test images: 9 %\n",
      "EPOCH 20\n",
      "Accuracy on the test images: 7 %\n",
      "Accuracy on the test images: 12 %\n",
      "EPOCH 21\n",
      "Accuracy on the test images: 13 %\n",
      "Accuracy on the test images: 15 %\n",
      "EPOCH 22\n",
      "Accuracy on the test images: 7 %\n",
      "Accuracy on the test images: 8 %\n",
      "EPOCH 23\n",
      "Accuracy on the test images: 8 %\n",
      "Accuracy on the test images: 12 %\n",
      "EPOCH 24\n",
      "Accuracy on the test images: 8 %\n",
      "Accuracy on the test images: 7 %\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = TripletLoss(20) # 选择损失函数\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    print('EPOCH ' + str(epoch))\n",
    "    # for step, (b_x, b_y) in enumerate(train_loader):\n",
    "    for step, (anchor, positive, negative) in enumerate(train_loader):\n",
    "        #output = cnn(b_x)[0]\n",
    "        #loss = loss_func(output, b_y)\n",
    "        anchor_output = cnn(anchor[0])[1]\n",
    "        positive_output = cnn(positive[0])[1]\n",
    "        negative_output = cnn(negative[0])[1]\n",
    "        #print(anchor_output.detach().numpy().shape)\n",
    "        \n",
    "        loss = loss_func(anchor_output, positive_output, negative_output)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for _, (test, _, _) in enumerate(test_loader):\n",
    "                test_output = cnn(test[0])[0]\n",
    "                predicted = torch.max(test_output, 1).indices\n",
    "                labels = test[1]\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            print('Accuracy on the test images: %d %%' % (100 * correct / total))\n",
    "            \n",
    "#             for data in test_loader:\n",
    "#                 images,labels = data\n",
    "#                 outputs = cnn(Variable(images))\n",
    "#                 predicted = torch.max(outputs[0], 1).indices\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum()\n",
    "                \n",
    "#             print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
