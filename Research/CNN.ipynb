{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2558bee2490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 25\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([   \n",
    "        transforms.Resize([96, 96]),  \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=(0,0,0),std=(1,1,1))\n",
    "])\n",
    "\n",
    "train_set = ImageFolder('./birds/train/',transform=transform)\n",
    "train_loader = Data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_set = ImageFolder('./birds/test/', transform=transform)\n",
    "test_loader = Data.DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross', '004.Groove_billed_Ani', '005.Crested_Auklet', '006.Least_Auklet', '007.Parakeet_Auklet', '008.Rhinoceros_Auklet', '009.Brewer_Blackbird', '010.Red_winged_Blackbird']\n",
      "{'001.Black_footed_Albatross': 0, '002.Laysan_Albatross': 1, '003.Sooty_Albatross': 2, '004.Groove_billed_Ani': 3, '005.Crested_Auklet': 4, '006.Least_Auklet': 5, '007.Parakeet_Auklet': 6, '008.Rhinoceros_Auklet': 7, '009.Brewer_Blackbird': 8, '010.Red_winged_Blackbird': 9}\n",
      "<bound method DatasetFolder.__len__ of Dataset ImageFolder\n",
      "    Number of datapoints: 543\n",
      "    Root location: ./birds/train/>\n",
      "['001.Black_footed_Albatross', '002.Laysan_Albatross', '003.Sooty_Albatross', '004.Groove_billed_Ani', '005.Crested_Auklet', '006.Least_Auklet', '007.Parakeet_Auklet', '008.Rhinoceros_Auklet', '009.Brewer_Blackbird', '010.Red_winged_Blackbird']\n",
      "{'001.Black_footed_Albatross': 0, '002.Laysan_Albatross': 1, '003.Sooty_Albatross': 2, '004.Groove_billed_Ani': 3, '005.Crested_Auklet': 4, '006.Least_Auklet': 5, '007.Parakeet_Auklet': 6, '008.Rhinoceros_Auklet': 7, '009.Brewer_Blackbird': 8, '010.Red_winged_Blackbird': 9}\n",
      "<bound method DatasetFolder.__len__ of Dataset ImageFolder\n",
      "    Number of datapoints: 113\n",
      "    Root location: ./birds/test/>\n"
     ]
    }
   ],
   "source": [
    "print(train_set.classes)\n",
    "print(train_set.class_to_idx)\n",
    "print(train_set.__len__)\n",
    "\n",
    "print(test_set.classes)\n",
    "print(test_set.class_to_idx)\n",
    "print(test_set.__len__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential( # 输入数据大小 (3,96,96)\n",
    "            nn.Conv2d(\n",
    "                in_channels=3, # 输入的图片层数\n",
    "                out_channels=16, # 卷积核数量\n",
    "                kernel_size=5, # 卷积核大小\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ), # 输出数据大小 (16,96,96)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential( # 输入数据大小 (16,48,48)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2), # 输出数据大小 (32,48,48)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 输出数据大小 (32,24,24)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(32*24*24, 32*24) # 全连接层\n",
    "        self.out = nn.Linear(32*24, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1) # 展平多维的卷积图\n",
    "        x = self.fc1(x)\n",
    "        output = self.out(x)\n",
    "        return output, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=18432, out_features=768, bias=True)\n",
      "  (out): Linear(in_features=768, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 10 %\n",
      "Accuracy of the network on the test images: 13 %\n",
      "Accuracy of the network on the test images: 18 %\n",
      "Accuracy of the network on the test images: 14 %\n",
      "Accuracy of the network on the test images: 15 %\n",
      "Accuracy of the network on the test images: 18 %\n",
      "Accuracy of the network on the test images: 20 %\n",
      "Accuracy of the network on the test images: 31 %\n",
      "Accuracy of the network on the test images: 23 %\n",
      "Accuracy of the network on the test images: 31 %\n",
      "Accuracy of the network on the test images: 32 %\n",
      "Accuracy of the network on the test images: 34 %\n",
      "Accuracy of the network on the test images: 34 %\n",
      "Accuracy of the network on the test images: 46 %\n",
      "Accuracy of the network on the test images: 50 %\n",
      "Accuracy of the network on the test images: 46 %\n",
      "Accuracy of the network on the test images: 59 %\n",
      "Accuracy of the network on the test images: 56 %\n",
      "Accuracy of the network on the test images: 56 %\n",
      "Accuracy of the network on the test images: 68 %\n",
      "Accuracy of the network on the test images: 57 %\n",
      "Accuracy of the network on the test images: 65 %\n",
      "Accuracy of the network on the test images: 79 %\n",
      "Accuracy of the network on the test images: 84 %\n",
      "Accuracy of the network on the test images: 79 %\n",
      "Accuracy of the network on the test images: 87 %\n",
      "Accuracy of the network on the test images: 89 %\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Accuracy of the network on the test images: 92 %\n",
      "Accuracy of the network on the test images: 89 %\n",
      "Accuracy of the network on the test images: 92 %\n",
      "Accuracy of the network on the test images: 95 %\n",
      "Accuracy of the network on the test images: 95 %\n",
      "Accuracy of the network on the test images: 97 %\n",
      "Accuracy of the network on the test images: 99 %\n",
      "Accuracy of the network on the test images: 99 %\n",
      "Accuracy of the network on the test images: 95 %\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Accuracy of the network on the test images: 93 %\n",
      "Accuracy of the network on the test images: 90 %\n",
      "Accuracy of the network on the test images: 88 %\n",
      "Accuracy of the network on the test images: 92 %\n",
      "Accuracy of the network on the test images: 97 %\n",
      "Accuracy of the network on the test images: 97 %\n",
      "Accuracy of the network on the test images: 99 %\n",
      "Accuracy of the network on the test images: 95 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "Accuracy of the network on the test images: 100 %\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss() # 选择损失函数\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    print('EPOCH ' + str(epoch))\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        output = cnn(b_x)[0]\n",
    "        loss = loss_func(output, b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for data in test_loader:\n",
    "                images,labels = data\n",
    "                outputs = cnn(Variable(images))\n",
    "                predicted = torch.max(outputs[0], 1).indices\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "            \n",
    "            \n",
    "print('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
